{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Language Processing Lab\n",
        "\n",
        "The objective of this task is to carry out various experiments to represent and classify tweets by their sentiment 3-class polarity (positive, neutral and negative). For this purpose, we will work with the same corpus used for the previous task, created for the [TASS 2020](http://www.sepln.org/workshops/tass/) competition (IberLEF - SEPLN). Different machine learning models will be comparated by their Macro-F1 results on the test set, and then we will compare our results with state-of-the-art python library [pysentimiento](https://github.com/pysentimiento/pysentimiento) for spanish sentiment analysis.\n",
        "\n",
        "\n",
        "Feature extraction tools used:\n",
        "\n",
        "- Word embeddings, mean vector, concatenation vector and adding context to these vectors (3 more values on each vector and these values indicate the class of the tweet).\n",
        "\n",
        "Machine learning models explored:\n",
        "\n",
        "- MLP\n",
        "- SVM\n",
        "- Logistic Regression\n",
        "- Naive Bayes\n",
        "- LSTM Neural networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Preprocessing\n",
        "We load tweets (train, dev, test) and a lexicon of positive and negative words. We also apply preprocessing: remove mentions and URLs, unify laugh patterns, replace insults, remove accents, convert to lowercase, and remove stopwords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this iteration of preprocessing, we will remove mentions and URLs, replacing them with an empty string (`\"\"`). For hashtags, we will only remove the `#` symbol without replacing it with the word \"HASHTAG.\" Tweets will be converted to lowercase, stopwords will be removed, numbers and accents will be eliminated, as these are deemed unnecessary for the objective.\n",
        "\n",
        "Swear words will be replaced with the word \"insulto,\" as it is included in the negative lexicon, emphasizing negative statements more effectively. Instead of replacing laughter patterns with \"jaja,\" we will use \"jajaja,\" which is included in the positive lexicon, unlike \"jaja.\"\n",
        "\n",
        "Accents will be removed again to standardize the tweets, as they are often inconsistently used. This approach will maximize the recognition of lexicon words in tweets. Unlike in Task 1, no syntactic analysis will be conducted, making accents and capitalization less relevant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# standard libraries\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# pysentimiento\n",
        "from pysentimiento import create_analyzer\n",
        "import transformers\n",
        "\n",
        "# custom imports\n",
        "from Logic import LSTMUtils, Preprocessing, build_custom_embeddings, load_fasttext\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "TRAIN_SET_PATH = 'data/train.csv'\n",
        "DEV_SET_PATH   = 'data/devel.csv'\n",
        "TEST_SET_PATH  = 'data/test.csv'\n",
        "\n",
        "POS_LEXICON_PATH = 'data/lexico_pos_lemas_grande.csv'\n",
        "NEG_LEXICON_PATH = 'data/lexico_neg_lemas_grande.csv'\n",
        "STOP_WORDS_PATH  = 'data/stop_words_esp_anasent.csv'\n",
        "WORD_VECTORS_PATH = 'data/cc.es.300.vec.gz' \n",
        "\n",
        "preprocessor = Preprocessing()\n",
        "lstm_utils = LSTMUtils()\n",
        "\n",
        "\n",
        "def load_csv(file_path, transform=None):\n",
        "    with open(file_path, newline='', encoding=\"utf-8\") as f:\n",
        "        reader = csv.reader(f)\n",
        "        next(reader)  # skip header\n",
        "        return [transform(row) if transform else row for row in reader]\n",
        "\n",
        "train_set = load_csv(TRAIN_SET_PATH)\n",
        "devel_set = load_csv(DEV_SET_PATH)\n",
        "test_set  = load_csv(TEST_SET_PATH)\n",
        "pos_set   = load_csv(POS_LEXICON_PATH)\n",
        "neg_set   = load_csv(NEG_LEXICON_PATH)\n",
        "stop_words_set = [row[0] for row in load_csv(STOP_WORDS_PATH)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tweet id: 168833726111956992\n",
            "Tweet: Listas de espera al alza en Catalunya, estallido en Grecia y debate #EntreTodos sobre la #refomalaboral. http://t.co/PIZAYzPe#portadaEPC\n",
            "Label: N\n"
          ]
        }
      ],
      "source": [
        "random_tweet = random.choice(train_set)\n",
        "print(f\"Tweet id: {random_tweet[0]}\")\n",
        "print(f\"Tweet: {random_tweet[1]}\")\n",
        "print(f\"Label: {random_tweet[2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Word Embeddings\n",
        "\n",
        "To represent tweets, models based on Word Embeddings will be used.\n",
        "\n",
        "* Each tweet represented as the **mean vector** of the word embeddings of its components.\n",
        "* Each tweet represented as the **concatenation** of the word embeddings of its components, resulting in a fixed-length vector.\n",
        "\n",
        "The word embedding collections are available at [Spanish Word Embeddings](https://github.com/dccuchile/spanish-word-embeddings). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom dictionary size: 9277\n",
            "Custom dictionary size: 9169\n"
          ]
        }
      ],
      "source": [
        "train_processed  = preprocessor.preprocess_corpus(train_set)\n",
        "devel_processed  = preprocessor.preprocess_corpus(devel_set)\n",
        "test_processed   = preprocessor.preprocess_corpus(test_set)\n",
        "\n",
        "train_processed_stopwords = preprocessor.preprocess_corpus(train_processed, stop_words_set)\n",
        "devel_processed_stopwords = preprocessor.preprocess_corpus(devel_processed, stop_words_set)\n",
        "test_processed_stopwords  = preprocessor.preprocess_corpus(test_processed, stop_words_set)\n",
        "\n",
        "small_fasttext = load_fasttext(WORD_VECTORS_PATH, limit=50000)\n",
        "custom_emb_dict = build_custom_embeddings(small_fasttext, train_processed, top_n=18000) \n",
        "custom_emb_dict_stopwords = build_custom_embeddings(small_fasttext, train_processed_stopwords, top_n=18000)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_lexicon = [x[0] for x in pos_set]\n",
        "neg_lexicon = [x[0] for x in neg_set]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Classical Models with Word Embeddings\n",
        "We can feed these embeddings into standard classifiers such as MLP, SVM, etc., using either the mean vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main_pipeline(\n",
        "    train_processed, \n",
        "    dev_processed, \n",
        "    custom_emb_dict, \n",
        "    lstm_utils,\n",
        "    train_model_with_random_search,\n",
        "    evaluate_model\n",
        "):\n",
        "    \"\"\"\n",
        "    Trains multiple machine learning models (MLP, SVM, Logistic Regression, Naive Bayes)\n",
        "    on mean-vector embeddings, optionally uses RandomizedSearchCV for hyperparameter tuning,\n",
        "    and evaluates each model with Macro-F1 on the development set.\n",
        "\n",
        "    Args:\n",
        "        train_processed (list): List of [id, preprocessed_text, label] for training.\n",
        "        dev_processed   (list): List of [id, preprocessed_text, label] for development.\n",
        "        custom_emb_dict (dict): Dictionary of custom word embeddings {token: vector}.\n",
        "        lstm_utils (object): Utility instance containing `preprocess_data_mean(...)`.\n",
        "        train_model_with_random_search (function): Function that performs a randomized search.\n",
        "        evaluate_model (function): Function to evaluate a trained model returning F1-score.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with model names as keys and Macro-F1 scores as values.\n",
        "    \"\"\"\n",
        "    train_X_mean, train_y_enc = lstm_utils.preprocess_data_mean(train_processed, custom_emb_dict)\n",
        "    dev_X_mean, dev_y_enc     = lstm_utils.preprocess_data_mean(dev_processed, custom_emb_dict)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    train_X_mean_scaled = scaler.fit_transform(train_X_mean)\n",
        "    dev_X_mean_scaled   = scaler.transform(dev_X_mean)\n",
        "\n",
        "    models = {\n",
        "        'MLP': (\n",
        "            MLPClassifier(max_iter=1000, random_state=123), \n",
        "            {\n",
        "                'hidden_layer_sizes': [(50,), (100,), (100, 50)],\n",
        "                'activation': ['tanh', 'relu'],\n",
        "                'alpha': [0.0001, 0.001, 0.01]\n",
        "            }\n",
        "        ),\n",
        "        'SVM': (\n",
        "            SVC(random_state=123), \n",
        "            {\n",
        "                'C': [0.1, 1, 10, 100],\n",
        "                'kernel': ['linear', 'rbf'],\n",
        "                'gamma': ['scale', 'auto']\n",
        "            }\n",
        "        ),\n",
        "        'Logistic Regression': (\n",
        "            LogisticRegression(max_iter=1000, random_state=123), \n",
        "            {\n",
        "                'C': [0.1, 1, 10, 100],\n",
        "                'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "                'solver': ['saga']\n",
        "            }\n",
        "        ),\n",
        "        'Naive Bayes': (\n",
        "            GaussianNB(), \n",
        "            {}  # No hyperparameters to tune\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for model_name, (model, param_distributions) in models.items():\n",
        "        print(f\"Training {model_name}...\")\n",
        "\n",
        "        if param_distributions:\n",
        "            best_model = train_model_with_random_search(\n",
        "                model, \n",
        "                param_distributions, \n",
        "                train_X_mean_scaled, \n",
        "                train_y_enc\n",
        "            )\n",
        "        else:\n",
        "            best_model = model.fit(train_X_mean_scaled, train_y_enc)\n",
        "\n",
        "        f1_score_macro = evaluate_model(best_model, dev_X_mean_scaled, dev_y_enc)\n",
        "        results[model_name] = f1_score_macro\n",
        "        print(f\"{model_name} Macro-F1: {f1_score_macro:.4f}\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training MLP...\n",
            "MLP Macro-F1: 0.5361\n",
            "Training SVM...\n",
            "SVM Macro-F1: 0.6044\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Macro-F1: 0.5910\n",
            "Training Naive Bayes...\n",
            "Naive Bayes Macro-F1: 0.4253\n"
          ]
        }
      ],
      "source": [
        "results = main_pipeline(train_processed, devel_processed, custom_emb_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. LSTM (Keras / TensorFlow) with Mean Vector and Concatenation Vector\n",
        "\n",
        "Next, we implement two LSTM variants:\n",
        "1. **LSTM with Mean Vector** (a single word embedding per tweet).\n",
        "2. **LSTM with Concat Sequence** (multiple time steps per tweet, up to a maximum `max_length`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_utils = LSTMUtils()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM Mean Vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.4211 - loss: 1.0745 - val_accuracy: 0.4885 - val_loss: 1.0283\n",
            "Epoch 2/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4953 - loss: 1.0166 - val_accuracy: 0.5115 - val_loss: 0.9892\n",
            "Epoch 3/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5200 - loss: 0.9816 - val_accuracy: 0.5345 - val_loss: 0.9667\n",
            "Epoch 4/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 0.9602 - val_accuracy: 0.5459 - val_loss: 0.9571\n",
            "Epoch 5/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5383 - loss: 0.9489 - val_accuracy: 0.5486 - val_loss: 0.9358\n",
            "Epoch 6/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5463 - loss: 0.9398 - val_accuracy: 0.5592 - val_loss: 0.9271\n",
            "Epoch 7/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5616 - loss: 0.9200 - val_accuracy: 0.5583 - val_loss: 0.9167\n",
            "Epoch 8/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5675 - loss: 0.9171 - val_accuracy: 0.5698 - val_loss: 0.9115\n",
            "Epoch 9/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5626 - loss: 0.9157 - val_accuracy: 0.5574 - val_loss: 0.9087\n",
            "Epoch 10/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5659 - loss: 0.9101 - val_accuracy: 0.5654 - val_loss: 0.9069\n",
            "Epoch 11/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 0.9074 - val_accuracy: 0.5777 - val_loss: 0.9011\n",
            "Epoch 12/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5736 - loss: 0.9021 - val_accuracy: 0.5795 - val_loss: 0.8959\n",
            "Epoch 13/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5787 - loss: 0.8880 - val_accuracy: 0.5804 - val_loss: 0.8942\n",
            "Epoch 14/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5839 - loss: 0.8909 - val_accuracy: 0.5760 - val_loss: 0.8916\n",
            "Epoch 15/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5768 - loss: 0.8913 - val_accuracy: 0.5813 - val_loss: 0.8913\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step \n",
            "LSTM (mean vector) Dev Macro-F1: 0.5764\n"
          ]
        }
      ],
      "source": [
        "# datasets\n",
        "train_X_mean_3d, train_y_mean = lstm_utils.build_mean_vector_dataset(train_processed, custom_emb_dict)\n",
        "dev_X_mean_3d, dev_y_mean = lstm_utils.build_mean_vector_dataset(devel_processed, custom_emb_dict)\n",
        "\n",
        "# label encoding\n",
        "train_y_mean_oh = lstm_utils.one_hot_3classes(train_y_mean)\n",
        "dev_y_mean_oh = lstm_utils.one_hot_3classes(dev_y_mean)\n",
        "\n",
        "# main training\n",
        "model_lstm_mean = lstm_utils.build_lstm_model_for_mean_vector(input_dim=302)\n",
        "history_mean = model_lstm_mean.fit(\n",
        "    train_X_mean_3d,\n",
        "    train_y_mean_oh,\n",
        "    validation_data=(dev_X_mean_3d, dev_y_mean_oh),\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# metrics\n",
        "dev_preds_mean = model_lstm_mean.predict(dev_X_mean_3d)\n",
        "dev_preds_labels_mean = np.argmax(dev_preds_mean, axis=1)\n",
        "dev_f1_mean = f1_score(dev_y_mean, dev_preds_labels_mean, average=\"macro\")\n",
        "print(f\"LSTM (mean vector) Dev Macro-F1: {dev_f1_mean:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LSTM Concat Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.4139 - loss: 1.0675 - val_accuracy: 0.5362 - val_loss: 0.9813\n",
            "Epoch 2/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.5119 - loss: 0.9957 - val_accuracy: 0.5663 - val_loss: 0.9405\n",
            "Epoch 3/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5586 - loss: 0.9311 - val_accuracy: 0.5777 - val_loss: 0.9194\n",
            "Epoch 4/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5672 - loss: 0.9055 - val_accuracy: 0.5751 - val_loss: 0.9045\n",
            "Epoch 5/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5770 - loss: 0.8887 - val_accuracy: 0.5707 - val_loss: 0.9029\n",
            "Epoch 6/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5864 - loss: 0.8885 - val_accuracy: 0.5919 - val_loss: 0.8899\n",
            "Epoch 7/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5982 - loss: 0.8631 - val_accuracy: 0.5989 - val_loss: 0.8915\n",
            "Epoch 8/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.5961 - loss: 0.8724 - val_accuracy: 0.5892 - val_loss: 0.8812\n",
            "Epoch 9/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6182 - loss: 0.8455 - val_accuracy: 0.6051 - val_loss: 0.8698\n",
            "Epoch 10/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6095 - loss: 0.8476 - val_accuracy: 0.6051 - val_loss: 0.8656\n",
            "Epoch 11/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6227 - loss: 0.8325 - val_accuracy: 0.5954 - val_loss: 0.8659\n",
            "Epoch 12/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6244 - loss: 0.8265 - val_accuracy: 0.6042 - val_loss: 0.8676\n",
            "Epoch 13/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6329 - loss: 0.8147 - val_accuracy: 0.6122 - val_loss: 0.8640\n",
            "Epoch 14/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6233 - loss: 0.8232 - val_accuracy: 0.6184 - val_loss: 0.8658\n",
            "Epoch 15/15\n",
            "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6310 - loss: 0.8185 - val_accuracy: 0.6175 - val_loss: 0.8574\n",
            "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "LSTM (concat vector) Dev Macro-F1: 0.6148\n"
          ]
        }
      ],
      "source": [
        "lstm_utils = LSTMUtils()\n",
        "\n",
        "MAX_LEN = 20 \n",
        "train_X_concat, train_y_concat = lstm_utils.build_concat_sequence_dataset(\n",
        "    train_processed, custom_emb_dict, max_length=MAX_LEN\n",
        ")\n",
        "dev_X_concat, dev_y_concat = lstm_utils.build_concat_sequence_dataset(\n",
        "    devel_processed, custom_emb_dict, max_length=MAX_LEN\n",
        ")\n",
        "\n",
        "train_y_concat_oh = lstm_utils.one_hot_3classes(train_y_concat)\n",
        "dev_y_concat_oh = lstm_utils.one_hot_3classes(dev_y_concat)\n",
        "\n",
        "model_lstm_concat = lstm_utils.build_lstm_model_for_concat_sequence(\n",
        "    max_length=MAX_LEN, embedding_dim=302\n",
        ")\n",
        "history_concat = model_lstm_concat.fit(\n",
        "    train_X_concat,\n",
        "    train_y_concat_oh,\n",
        "    validation_data=(dev_X_concat, dev_y_concat_oh),\n",
        "    epochs=15,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "dev_preds_concat = model_lstm_concat.predict(dev_X_concat)\n",
        "dev_preds_labels_concat = np.argmax(dev_preds_concat, axis=1)\n",
        "dev_f1_concat = f1_score(dev_y_concat, dev_preds_labels_concat, average=\"macro\")\n",
        "print(f\"LSTM (concat vector) Dev Macro-F1: {dev_f1_concat:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation on Test and Comparison with PySentimiento\n",
        "Finalmente, evaluamos en el test set (con la misma representación que en train). Luego comparamos con un modelo pretrained de [pysentimiento](https://github.com/pysentimiento)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "LSTM (mean vector) Test Macro-F1: 0.5795\n",
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
            "LSTM (concat vector) Test Macro-F1: 0.5974\n"
          ]
        }
      ],
      "source": [
        "test_X_mean_3d, test_y_mean = lstm_utils.build_mean_vector_dataset(test_processed, custom_emb_dict)\n",
        "test_y_mean_oh = lstm_utils.one_hot_3classes(test_y_mean)\n",
        "\n",
        "\n",
        "pred_probs_mean = model_lstm_mean.predict(test_X_mean_3d)\n",
        "pred_labels_mean = np.argmax(pred_probs_mean, axis=1)\n",
        "test_f1_mean = f1_score(test_y_mean, pred_labels_mean, average=\"macro\")\n",
        "print(f\"LSTM (mean vector) Test Macro-F1: {test_f1_mean:.4f}\")\n",
        "\n",
        "test_X_concat, test_y_concat = lstm_utils.build_concat_sequence_dataset(\n",
        "    test_processed, custom_emb_dict, max_length=MAX_LEN\n",
        ")\n",
        "test_y_concat_oh = lstm_utils.one_hot_3classes(test_y_concat)\n",
        "\n",
        "pred_probs_concat = model_lstm_concat.predict(test_X_concat)\n",
        "pred_labels_concat = np.argmax(pred_probs_concat, axis=1)\n",
        "test_f1_concat = f1_score(test_y_concat, pred_labels_concat, average=\"macro\")\n",
        "print(f\"LSTM (concat vector) Test Macro-F1: {test_f1_concat:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\repos\\IPLN\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PySentimiento Test Macro-F1: 0.6963\n"
          ]
        }
      ],
      "source": [
        "transformers.logging.set_verbosity_error()\n",
        "\n",
        "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "def convert_pysentimiento_label(label):\n",
        "    if label == 'POS':\n",
        "        return 0\n",
        "    elif label == 'NEG':\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "pys_preds = []\n",
        "test_labels_for_pys = lstm_utils.encode_label([x[2] for x in test_processed])\n",
        "\n",
        "for row in test_processed:\n",
        "    text = row[1]\n",
        "    res  = analyzer.predict(text)\n",
        "    pys_preds.append(convert_pysentimiento_label(res.output))\n",
        "\n",
        "pys_f1 = f1_score(test_labels_for_pys, pys_preds, average='macro')\n",
        "print(\"PySentimiento Test Macro-F1:\", f'{pys_f1:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
